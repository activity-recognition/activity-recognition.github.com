---
layout: pagenav
title: "Sharing"
tagline: "all the code/data/... etc. you ever wanted"
description: ""
group: navigation
navside: ["Data_sets","Code_and_Manuals"]

navigation:
  title: Sharing
  weight: 350
  show: true

---

#Data Sets
[The Opportunity Dataset](http://contextdb.org)
The OPPORTUNITY activity recognition dataset has been recorded to recognize complex activities in highly rich sensor environments, thus allowing to simulate opportunistic sensor configurations. The recognition scenario is a breakfast scenario with a rich set of activity primitives, and high level activities. The dataset contains the recordings of 72 sensors of 10 modalities distributed in 15 sensor networks. Twelve subjects participated to the recordings, with 5 "breakfast runs" per subject, and a "drill run" dedicated to generate a lot of activity primitives (~2.5hrs/subject). Over 11000 and 17000 object and environment interactions occurred during the recording.


[Placelab Dataset](http://architecture.mit.edu/house_n/data/PlaceLab/PlaceLab.htm)
The PlaceLab is a unique live-in laboratory in Cambridge, MA. It is a joint MIT House_n and TIAX, LLC initiative. This website is intended for researchers interested in becoming more familiar with PlaceLab data and possibly using the data in their own work. The PlaceLab was first introduced in a CHI 2005 paper.

#Code and Manuals
[CRN Toolbox](http://crnt.sourceforge.net/)
The Context Recognition Network (CRN) Toolbox allows to quickly build distributed, multi-modal context recognition systems by simply plugging together reusable, parameterizable components.


[Snsrlog](https://github.com/kkai/snsrlog)
An iOS app to view, record and stream sensor data in real-time.


[Pedestrian Deadreckoning Implementation](https://github.com/kkai/reckonMe)
Live inertial navigation, proximity detection and collaborative localisation on a mobile device (iOS).


