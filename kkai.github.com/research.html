<p>My research work centers around how to extract high level information about the user’s activities and his current situation utilizing sensors embedded into every day appliances. The inferred high level information (“context”) enables pro-active systems minimizing direct user interaction.</p>

<h2 id='participatory_sensing_and_big_data'>participatory sensing and big data</h2>

<p>Our everyday lives get more and more saturated with computing devices and embedded sensors. With access to powerful smart phones, sensors embedded into all types of intelligent objects and a ubiquitous Internet, large ensembles of users and devices may dynamically form, cooperate and interact with each other not bound to space or time. Given this rich crowd-sourced data and, most important, the appropriate aggregations, visualizations and user interfaces, the user could not only improve his own lifestyle, but the living conditions of a whole city or region leveraging sensor traces from smart phones, traffic, infrastructure etc. combined with other sources like social media data.</p>

<h2 id='dynamic_selfadapting_context_recognition'>dynamic, self-adapting context recognition</h2>

<p>Today, with few exceptions, the state of the art approaches to context recognition assume dedicated sensing devices with fixed locations which are often carefully chosen to suit a particular application. This is a major limitation hindering wide-spread adoption of context recognition systems. In my phD. thesis, I presented a systematic evaluation of device placement effects in context recognition. In the course of my thesis, I developed methods,</p>

<ul>
<li>to detect if a device is carried on the body or placed at a specific location in the environment (on a wooden table, in a closed metal compartment etc.),</li>

<li>to infer the coarse on-body location (on the wrist, on the torso, &#8230;) of a device, solely based on rotation and acceleration signals of the device)</li>

<li>to utilize heuristics that significantly increase the robustness of motion sensor-based activity recognition with respect to sensor displacement.</li>

<li>to detect the orientation of a device related to the user’s body.</li>
</ul>

<p>All methods have been empirically evaluated in elaborate, realistic experimental setups or application scenarios. I try to pick application domains that provide a scientific challenge and have some broader social importance (e.g. from assistant living, over work process support to emergency response). A second theme in my research is the quantitative evaluation of the benefit pervasive context recognition systems bring to diverse applications. Up to now, I tackled the domain of wearable maintenance systems and activity logging systems for hospital documentation purposes. Working with real maintenance workers at the Carl Zeiss AG trying to support their everyday work, let me realize that although implementing context recognition systems is already difficult, the real challenge is the user interface aspect of pro-active pervasive systems. There is the high risk of performing unnecessary or unwanted actions leaving the user alienated.</p>